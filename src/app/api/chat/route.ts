import { GoogleGenerativeAI } from '@google/generative-ai'
import { NextRequest, NextResponse } from 'next/server'

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '')

const SYSTEM_PROMPT = `ë‹¹ì‹ ì€ "ì„±ê²½ì¹œêµ¬"ë¼ëŠ” ì´ë¦„ì˜ ì¹œì ˆí•œ ì£¼ì¼í•™êµ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
7ì‚´ ì •ë„ì˜ í•œêµ­ ì–´ë¦°ì´ì—ê²Œ ì„±ê²½ ì´ì•¼ê¸°ë¥¼ ì„¤ëª…í•´ì£¼ëŠ” ì—­í• ì…ë‹ˆë‹¤.

ê·œì¹™:
- ì‰¬ìš´ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ì„¸ìš” (ì–´ë ¤ìš´ ë‹¨ì–´ ì‚¬ìš© ê¸ˆì§€)
- ë‹µë³€ì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ í•´ì£¼ì„¸ìš”
- í•­ìƒ ë”°ëœ»í•˜ê³  ê²©ë ¤í•˜ëŠ” ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ì‹¤ì œ ì„±ê²½ êµ¬ì ˆì„ ì¸ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: ì°½ì„¸ê¸° 1:1)
- ì„±ê²½ê³¼ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” "ê·¸ê±´ ì„±ê²½ ì´ì•¼ê¸°ê°€ ì•„ë‹ˆì§€ë§Œ..." í•˜ê³  ë¶€ë“œëŸ½ê²Œ ë‹µí•´ì£¼ì„¸ìš”
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ì„œ ì¹œê·¼í•˜ê²Œ í•´ì£¼ì„¸ìš”
- ë¬´ì„œìš´ ë‚´ìš©ì€ ë¶€ë“œëŸ½ê²Œ ìˆœí™”í•´ì„œ ì„¤ëª…í•˜ì„¸ìš”`

export async function POST(req: NextRequest) {
  try {
    const { message, history } = await req.json()

    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' })

    const chatHistory = (history || []).map((m: { role: string; text: string }) => ({
      role: m.role === 'ai' ? 'model' : 'user',
      parts: [{ text: m.text }],
    }))

    const chat = model.startChat({
      history: [
        { role: 'user', parts: [{ text: SYSTEM_PROMPT }] },
        { role: 'model', parts: [{ text: 'ë„¤, ì•Œê² ìŠµë‹ˆë‹¤! ì €ëŠ” ì„±ê²½ì¹œêµ¬ì˜ˆìš”. ì–´ë¦°ì´ë“¤ì—ê²Œ ì„±ê²½ì„ ì‰½ê³  ì¬ë¯¸ìˆê²Œ ì•Œë ¤ì¤„ê²Œìš”! ğŸ˜Š' }] },
        ...chatHistory,
      ],
    })

    const result = await chat.sendMessage(message)
    const reply = result.response.text()

    return NextResponse.json({ reply })
  } catch (error) {
    console.error('Chat API error:', error)
    return NextResponse.json({ reply: 'ë¯¸ì•ˆí•´ìš”, ì ì‹œ ì˜¤ë¥˜ê°€ ë‚¬ì–´ìš”. ë‹¤ì‹œ ë¬¼ì–´ë´ ì£¼ì„¸ìš”! ğŸ™' }, { status: 500 })
  }
}
